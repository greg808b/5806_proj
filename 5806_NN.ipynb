{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c1ef46",
   "metadata": {},
   "source": [
    "Actual model performance on the data happens much further down\n",
    "\n",
    " -Where elite_predit is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0985219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "859e41fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#grab training data\n",
    "data_playoffs = pd.read_excel(\"./teams_cluster_min_playoffs.xlsx\",index_col = \"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b16b3719-d8f1-4fe9-87ac-b06f0953cc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#grab training data\n",
    "data_playoffs = pd.read_excel(\"./teams_cluster_min_playoffs_10.xlsx\", index_col =\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae066697",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_playoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c52665f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abf6f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ef8e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = data_playoffs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fa2686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data from labels\n",
    "data_inputx = data_arr[:,0:10]\n",
    "data_inputy = data_arr[:,10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d23e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into diff sections based on input number\n",
    "def split(run_num):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_inputx, data_inputy, test_size=0.20, random_state=run_num)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ed4a05e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(5,), learning_rate_init=0.01, max_iter=10000,\n",
       "              random_state=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(5,), learning_rate_init=0.01, max_iter=10000,\n",
       "              random_state=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(5,), learning_rate_init=0.01, max_iter=10000,\n",
       "              random_state=7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating model for actual predictions\n",
    "x_train, x_test, y_train, y_test = split(7)\n",
    "hidden = 5\n",
    "learn_rate = 0.01\n",
    "nn = MLPClassifier(hidden_layer_sizes=(hidden,), random_state=7, max_iter=10000,solver='adam', learning_rate_init=learn_rate)\n",
    "nn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5589da39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(30,), max_iter=10000, random_state=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(30,), max_iter=10000, random_state=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30,), max_iter=10000, random_state=7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating our model for actual predictions\n",
    "hidden1 = 30\n",
    "learn_rate1 = 0.001\n",
    "nn1 = MLPClassifier(hidden_layer_sizes=(hidden1,), random_state=7, max_iter=10000,solver='adam', learning_rate_init=learn_rate1)\n",
    "nn1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c773b7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6934306569343066 0.6861313868613139\n"
     ]
    }
   ],
   "source": [
    "#scoring the two models against eachother\n",
    "score = nn.score(x_test, y_test) #original\n",
    "score1 = nn1.score(x_test, y_test) #modified\n",
    "print(score, score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58699fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#necessary for eval\n",
    "m_0 = nn.coefs_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdc24e16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.43179912,  0.53422033,  0.13760262,  0.0424074 ,  0.1212001 ],\n",
       "       [ 0.41041828, -0.04185294, -4.57988243, -0.33529196,  1.71327685],\n",
       "       [ 0.29726616,  1.02308336,  1.10750562, -0.48628729, -0.35336925],\n",
       "       [ 0.62175518, -0.23260367,  0.64429062,  0.27380594, -0.1123867 ],\n",
       "       [-0.18360074,  0.43450547, -2.61073672, -0.05138342,  1.8917474 ],\n",
       "       [ 0.42792388,  0.57185513,  0.22374433,  0.08398474,  1.50884391],\n",
       "       [-0.57608247, -0.06847289, -0.49024225, -0.11844496,  1.29046722],\n",
       "       [ 0.6431495 ,  0.7070728 , -0.05703906,  0.00837265, -2.01652218],\n",
       "       [ 0.89355519,  0.00852054,  1.00442004, -0.3419858 ,  0.01523325],\n",
       "       [ 1.25530601,  0.74768965, -0.45313621, -0.44523236,  1.24957751]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18f176dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m_0 = pd.DataFrame(m_0,columns=[\"H1\",\"H2\",\"H3\",\"H4\",\"H5\",\"H6\",\"H7\",\"H8\",\"H9\",\"H10\",\"H11\",\"H12\",\"H13\",\"H14\",\"H15\"],index = [\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d58a0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m_0 = pd.DataFrame(m_0,columns=[\"H1\",\"H2\",\"H3\",\"H4\",\"H5\"],index = [\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c0bcbc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#necessary for eval\n",
    "m_1 = nn.coefs_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76f4515b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7826aac4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#take in data\n",
    "elite_predict = pd.read_excel(\"./nn_predict_data.xlsx\",sheet_name= 'elite',index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd71645f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#take in data\n",
    "elite_predict = pd.read_excel(\"./nn_elite_predict_data_10.xlsx\",index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b270267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster0</th>\n",
       "      <th>Cluster1</th>\n",
       "      <th>Cluster2</th>\n",
       "      <th>Cluster3</th>\n",
       "      <th>Cluster4</th>\n",
       "      <th>Cluster5</th>\n",
       "      <th>Cluster6</th>\n",
       "      <th>Cluster7</th>\n",
       "      <th>Cluster8</th>\n",
       "      <th>Cluster9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elite</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-0</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-0</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-1</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-0</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-1</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-2</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cluster0  Cluster1  Cluster2  Cluster3  Cluster4  Cluster5  Cluster6  \\\n",
       "elite                                                                         \n",
       "1-0    0.145833  0.106771  0.106771  0.000000  0.106771  0.106771  0.106771   \n",
       "0-1    0.000000  0.106771  0.106771  0.145833  0.106771  0.106771  0.106771   \n",
       "2-0    0.291667  0.088542  0.088542  0.000000  0.088542  0.088542  0.088542   \n",
       "1-1    0.145833  0.088542  0.088542  0.145833  0.088542  0.088542  0.088542   \n",
       "0-2    0.000000  0.088542  0.088542  0.291667  0.088542  0.088542  0.088542   \n",
       "3-0    0.437500  0.070312  0.070312  0.000000  0.070312  0.070312  0.070312   \n",
       "2-1    0.291667  0.070312  0.070312  0.145833  0.070312  0.070312  0.070312   \n",
       "1-2    0.145833  0.070312  0.070312  0.291667  0.070312  0.070312  0.070312   \n",
       "0-3    0.000000  0.070312  0.070312  0.437500  0.070312  0.070312  0.070312   \n",
       "\n",
       "       Cluster7  Cluster8  Cluster9  \n",
       "elite                                \n",
       "1-0    0.106771  0.106771  0.106771  \n",
       "0-1    0.106771  0.106771  0.106771  \n",
       "2-0    0.088542  0.088542  0.088542  \n",
       "1-1    0.088542  0.088542  0.088542  \n",
       "0-2    0.088542  0.088542  0.088542  \n",
       "3-0    0.070312  0.070312  0.070312  \n",
       "2-1    0.070312  0.070312  0.070312  \n",
       "1-2    0.070312  0.070312  0.070312  \n",
       "0-3    0.070312  0.070312  0.070312  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elite_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78b92d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elite_predict_arr = elite_predict.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "645a5cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#applying model coefficients to the values\n",
    "prob = sigmoid(np.matmul(sigmoid(np.matmul(elite_predict_arr,m_0)),m_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "630cfad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create new column with prediction values\n",
    "elite_predict[\"prob\"] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05affd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster0</th>\n",
       "      <th>Cluster1</th>\n",
       "      <th>Cluster2</th>\n",
       "      <th>Cluster3</th>\n",
       "      <th>Cluster4</th>\n",
       "      <th>Cluster5</th>\n",
       "      <th>Cluster6</th>\n",
       "      <th>Cluster7</th>\n",
       "      <th>Cluster8</th>\n",
       "      <th>Cluster9</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elite</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-0</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.612927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.597508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-0</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.660109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-1</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.645168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.631155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-0</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.704343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-1</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.691198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-2</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.677515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.664710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cluster0  Cluster1  Cluster2  Cluster3  Cluster4  Cluster5  Cluster6  \\\n",
       "elite                                                                         \n",
       "1-0    0.145833  0.106771  0.106771  0.000000  0.106771  0.106771  0.106771   \n",
       "0-1    0.000000  0.106771  0.106771  0.145833  0.106771  0.106771  0.106771   \n",
       "2-0    0.291667  0.088542  0.088542  0.000000  0.088542  0.088542  0.088542   \n",
       "1-1    0.145833  0.088542  0.088542  0.145833  0.088542  0.088542  0.088542   \n",
       "0-2    0.000000  0.088542  0.088542  0.291667  0.088542  0.088542  0.088542   \n",
       "3-0    0.437500  0.070312  0.070312  0.000000  0.070312  0.070312  0.070312   \n",
       "2-1    0.291667  0.070312  0.070312  0.145833  0.070312  0.070312  0.070312   \n",
       "1-2    0.145833  0.070312  0.070312  0.291667  0.070312  0.070312  0.070312   \n",
       "0-3    0.000000  0.070312  0.070312  0.437500  0.070312  0.070312  0.070312   \n",
       "\n",
       "       Cluster7  Cluster8  Cluster9      prob  \n",
       "elite                                          \n",
       "1-0    0.106771  0.106771  0.106771  0.612927  \n",
       "0-1    0.106771  0.106771  0.106771  0.597508  \n",
       "2-0    0.088542  0.088542  0.088542  0.660109  \n",
       "1-1    0.088542  0.088542  0.088542  0.645168  \n",
       "0-2    0.088542  0.088542  0.088542  0.631155  \n",
       "3-0    0.070312  0.070312  0.070312  0.704343  \n",
       "2-1    0.070312  0.070312  0.070312  0.691198  \n",
       "1-2    0.070312  0.070312  0.070312  0.677515  \n",
       "0-3    0.070312  0.070312  0.070312  0.664710  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elite_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5647cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the others table\n",
    "other_predict = pd.read_excel(\"./nn_predict_data.xlsx\",sheet_name= 'other',index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3802456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster1</th>\n",
       "      <th>Cluster2</th>\n",
       "      <th>Cluster3</th>\n",
       "      <th>Cluster4</th>\n",
       "      <th>Cluster5</th>\n",
       "      <th>Cluster6</th>\n",
       "      <th>Cluster7</th>\n",
       "      <th>Cluster8</th>\n",
       "      <th>Cluster9</th>\n",
       "      <th>Cluster10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cluster1  Cluster2  Cluster3  Cluster4  Cluster5  Cluster6  Cluster7  \\\n",
       "other                                                                         \n",
       "2      0.145833  0.708333  0.000000  0.000000         0  0.000000  0.000000   \n",
       "3      0.145833  0.000000  0.708333  0.000000         0  0.000000  0.000000   \n",
       "4      0.145833  0.000000  0.000000  0.708333         0  0.000000  0.000000   \n",
       "6      0.145833  0.000000  0.000000  0.000000         0  0.708333  0.000000   \n",
       "7      0.145833  0.000000  0.000000  0.000000         0  0.000000  0.708333   \n",
       "9      0.145833  0.000000  0.000000  0.000000         0  0.000000  0.000000   \n",
       "10     0.145833  0.000000  0.000000  0.000000         0  0.000000  0.000000   \n",
       "\n",
       "       Cluster8  Cluster9  Cluster10  \n",
       "other                                 \n",
       "2      0.145833  0.000000   0.000000  \n",
       "3      0.145833  0.000000   0.000000  \n",
       "4      0.145833  0.000000   0.000000  \n",
       "6      0.145833  0.000000   0.000000  \n",
       "7      0.145833  0.000000   0.000000  \n",
       "9      0.145833  0.708333   0.000000  \n",
       "10     0.145833  0.000000   0.708333  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "18397be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as with elite_predict\n",
    "other_predict_arr = other_predict.to_numpy()\n",
    "prob = sigmoid(np.matmul(sigmoid(np.matmul(other_predict_arr,m_0)),m_1))\n",
    "other_predict[\"prob\"] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b65aa085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster1</th>\n",
       "      <th>Cluster2</th>\n",
       "      <th>Cluster3</th>\n",
       "      <th>Cluster4</th>\n",
       "      <th>Cluster5</th>\n",
       "      <th>Cluster6</th>\n",
       "      <th>Cluster7</th>\n",
       "      <th>Cluster8</th>\n",
       "      <th>Cluster9</th>\n",
       "      <th>Cluster10</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.464795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cluster1  Cluster2  Cluster3  Cluster4  Cluster5  Cluster6  Cluster7  \\\n",
       "other                                                                         \n",
       "2      0.145833  0.708333  0.000000  0.000000         0  0.000000  0.000000   \n",
       "3      0.145833  0.000000  0.708333  0.000000         0  0.000000  0.000000   \n",
       "4      0.145833  0.000000  0.000000  0.708333         0  0.000000  0.000000   \n",
       "6      0.145833  0.000000  0.000000  0.000000         0  0.708333  0.000000   \n",
       "7      0.145833  0.000000  0.000000  0.000000         0  0.000000  0.708333   \n",
       "9      0.145833  0.000000  0.000000  0.000000         0  0.000000  0.000000   \n",
       "10     0.145833  0.000000  0.000000  0.000000         0  0.000000  0.000000   \n",
       "\n",
       "       Cluster8  Cluster9  Cluster10      prob  \n",
       "other                                           \n",
       "2      0.145833  0.000000   0.000000  0.457211  \n",
       "3      0.145833  0.000000   0.000000  0.321449  \n",
       "4      0.145833  0.000000   0.000000  0.627796  \n",
       "6      0.145833  0.000000   0.000000  0.661097  \n",
       "7      0.145833  0.000000   0.000000  0.301728  \n",
       "9      0.145833  0.708333   0.000000  0.695589  \n",
       "10     0.145833  0.000000   0.708333  0.464795  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36b7d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make MLP models given all input values and record testing and training accuracy\n",
    "def scipy_nn(x_train, x_test, y_train, y_test, type_model, hidden, learn_rate, run_num):\n",
    "    if type_model ==0: #SGD\n",
    "        nn = MLPClassifier(hidden_layer_sizes=(hidden,), random_state=run_num, max_iter=10000,solver='sgd',  learning_rate_init=learn_rate )    \n",
    "    elif type_model ==1: #Adam\n",
    "        nn = MLPClassifier(hidden_layer_sizes=(hidden,), random_state=run_num, max_iter=10000,solver='adam', learning_rate_init=learn_rate)\n",
    "    nn.fit(x_train, y_train)\n",
    "    y_pred_test = nn.predict(x_test)\n",
    "    y_pred_train = nn.predict(x_train)\n",
    "    acc_test = accuracy_score(y_pred_test, y_test) \n",
    "    acc_train = accuracy_score(y_pred_train, y_train)\n",
    "    return (acc_test , acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2354e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate training and testing accuracy from touple\n",
    "def separate(data):\n",
    "    test = []\n",
    "    train = []\n",
    "    for _x in data:\n",
    "        test.append(_x[0])\n",
    "        train.append(_x[1])\n",
    "\n",
    "    return (test,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5215b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up data storage for performance models\n",
    "max_expruns = 15\n",
    "SGD_all = np.zeros((max_expruns,2)) \n",
    "SGD1_all = np.zeros((max_expruns,2)) \n",
    "Adam_all = np.zeros((max_expruns,2))\n",
    "Adam1_all = np.zeros((max_expruns,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0116120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for the NN\n",
    "#default and modified\n",
    "hidden = 5\n",
    "learn_rate = 0.01\n",
    "hidden1 = 30\n",
    "learn_rate1 = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d7f233b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#run the first models max_expruns times and record results\n",
    "#this runs two original and two modified of same library\n",
    "for run_num in range(0,max_expruns):\n",
    "    x_train, x_test, y_train, y_test = split(run_num)\n",
    "    acc_sgd = scipy_nn(x_train, x_test, y_train, y_test, 0, hidden, learn_rate, run_num) #SGD\n",
    "    acc_sgd1 = scipy_nn(x_train, x_test, y_train, y_test, 0, hidden1, learn_rate1, run_num) #SGD mod\n",
    "    acc_adam = scipy_nn(x_train, x_test, y_train, y_test, 1, hidden, learn_rate, run_num) #Adam        \n",
    "    acc_adam1 = scipy_nn(x_train, x_test, y_train, y_test, 1, hidden1, learn_rate1, run_num) #Adam  mod      \n",
    "    SGD_all[run_num] = acc_sgd\n",
    "    SGD1_all[run_num] = acc_sgd1\n",
    "    Adam_all[run_num] = acc_adam  \n",
    "    Adam1_all[run_num] = acc_adam1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2182f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record the test and training scores from data\n",
    "sgd_test, sgd_train = separate(SGD_all)\n",
    "sgd1_test, sgd1_train = separate(SGD1_all)\n",
    "adam_test, adam_train = separate(Adam_all)\n",
    "adam1_test, adam1_train = separate(Adam1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78bf48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not used. will stop the model from overfitting\n",
    "from keras.callbacks import EarlyStopping\n",
    "usualCallback = EarlyStopping()\n",
    "overfitCallback = EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=10, start_from_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee0c0e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     x_train1, x_test1, y_train1, y_test1 \u001b[38;5;241m=\u001b[39m split(run_num)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#sgd\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(hidden1, input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#     model.add(keras.layers.Dense(hidden1, input_dim=10, activation='relu'))\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "#using keras library for the NN\n",
    "#change input dimension based on # of clusters\n",
    "#performs max_expruns runs on the same models recoring test and training accuracy\n",
    "sgd_keras = []\n",
    "adam_keras = []\n",
    "for run_num in range(0,max_expruns):\n",
    "    x_train1, x_test1, y_train1, y_test1 = split(run_num)\n",
    "    #sgd\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(hidden1, input_dim=10, activation='relu'))\n",
    "#     model.add(keras.layers.Dense(hidden1, input_dim=10, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    sgd = keras.optimizers.SGD(learning_rate=learn_rate1)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['acc'])\n",
    "    model.fit(x_train1, y_train1, epochs=25, batch_size=150, verbose=0)#, callbacks=[overfitCallback])\n",
    "    sgd_keras.append((model.evaluate(x_test1,y_test1)[1]))\n",
    "    \n",
    "    \n",
    "    #adam\n",
    "    model1 = keras.Sequential()\n",
    "    model1.add(keras.layers.Dense(hidden1, input_dim=10, activation='relu'))\n",
    "#     model.add(keras.layers.Dense(hidden1, input_dim=10, activation='relu'))\n",
    "    model1.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    adam = keras.optimizers.Adam(learning_rate=learn_rate1)\n",
    "    model1.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "    model1.fit(x_train1, y_train1, epochs=25, batch_size=150, verbose=0)#, callbacks=[overfitCallback])\n",
    "    adam_keras.append((model1.evaluate(x_test1,y_test1)[1]))\n",
    "    \n",
    "    print(run_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87daa290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results as boxplots with mean\n",
    "\n",
    "import pylab as P\n",
    "P.figure()\n",
    "bp = P.boxplot((sgd_test, adam_test, sgd1_test, adam1_test, sgd_keras, adam_keras), labels=('sgd_orig',\n",
    "                     'adam_orig', 'sgd1_test', 'adam1_test','sgd_keras', 'adam_keras'))\n",
    "list = [np.mean(sgd_test), np.mean(adam_test), np.mean(sgd1_test),np.mean(adam1_test) ,np.mean(sgd_keras) ,np.mean(adam_keras)]\n",
    "for i in range(0,6):\n",
    "    P.plot(i+1,list[i], '.r')\n",
    "P.title(f\"hidden#={hidden1} and lr={learn_rate1}\")\n",
    "\n",
    "P.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "x_train1, x_test1, y_train1, y_test1 = split(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c95385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing development of just one model\n",
    "#not necessary\n",
    "model_test = keras.Sequential()\n",
    "model_test.add(keras.layers.Dense(hidden1, input_dim=10, activation='relu'))\n",
    "# model_test.add(keras.layers.Dense(hidden1, input_dim=1, activation='relu'))\n",
    "model_test.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "sgd = keras.optimizers.SGD(learning_rate=learn_rate1)\n",
    "model_test.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['acc'])\n",
    "history = model_test.fit(x_train1, y_train1, epochs=150, batch_size=200, verbose=0, \n",
    "                    validation_data = (x_test1,y_test1), callbacks=[overfitCallback])\n",
    "model_test.evaluate(x_test1,y_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0b863",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plotting the accuracy performance of singular model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6a917",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe043281",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.3f, %.3f, %.3f, %.3f, %.3f, %.3f' %(np.mean(sgd_test), np.mean(adam_test), np.mean(sgd1_test),np.mean(adam1_test) ,np.mean(accuracies) ,np.mean(accuracies1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
